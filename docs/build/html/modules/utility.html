<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Utility &mdash; giotto-deep 0.0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=f6245a2f"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Topology Layers" href="topology_layers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            giotto-deep
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">Distributed computing</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="analysis.html">Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="trainer.html">Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="search.html">Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="topology_layers.html">Topology Layers</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Utility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.ActivationFunction"><code class="docutils literal notranslate"><span class="pre">ActivationFunction</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.AttentionType"><code class="docutils literal notranslate"><span class="pre">AttentionType</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.KnownWarningSilencer"><code class="docutils literal notranslate"><span class="pre">KnownWarningSilencer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.LayerNormStyle"><code class="docutils literal notranslate"><span class="pre">LayerNormStyle</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.PoolerType"><code class="docutils literal notranslate"><span class="pre">PoolerType</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.autoreload_if_notebook"><code class="docutils literal notranslate"><span class="pre">autoreload_if_notebook()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.ensemble_wrapper"><code class="docutils literal notranslate"><span class="pre">ensemble_wrapper()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.get_parameter_types"><code class="docutils literal notranslate"><span class="pre">get_parameter_types()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.get_return_type"><code class="docutils literal notranslate"><span class="pre">get_return_type()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.is_notebook"><code class="docutils literal notranslate"><span class="pre">is_notebook()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.save_model_and_optimizer"><code class="docutils literal notranslate"><span class="pre">save_model_and_optimizer()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdeep.utility.torch_transform"><code class="docutils literal notranslate"><span class="pre">torch_transform()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-gdeep.utility.optimization">Persistence Gradient</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gdeep.utility.optimization.MissingClosureError"><code class="docutils literal notranslate"><span class="pre">MissingClosureError</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#gdeep.utility.optimization.PersistenceGradient"><code class="docutils literal notranslate"><span class="pre">PersistenceGradient</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#gdeep.utility.optimization.SAM"><code class="docutils literal notranslate"><span class="pre">SAM</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#gdeep.utility.optimization.SAMOptimizer"><code class="docutils literal notranslate"><span class="pre">SAMOptimizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-gdeep.utility.extended_persistence">Extended Persistence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gdeep.utility.extended_persistence.graph_extended_persistence_hks"><code class="docutils literal notranslate"><span class="pre">graph_extended_persistence_hks()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#references">References</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">giotto-deep</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">API reference</a></li>
      <li class="breadcrumb-item active">Utility</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/modules/utility.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="utility">
<h1>Utility<a class="headerlink" href="#utility" title="Permalink to this heading"></a></h1>
<span class="target" id="module-gdeep.utility"></span><dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.ActivationFunction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">ActivationFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.ActivationFunction" title="Permalink to this definition"></a></dt>
<dd><p>The activation function.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.AttentionType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">AttentionType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.AttentionType" title="Permalink to this definition"></a></dt>
<dd><p>The type of attention.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.KnownWarningSilencer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">KnownWarningSilencer</span></span><a class="headerlink" href="#gdeep.utility.KnownWarningSilencer" title="Permalink to this definition"></a></dt>
<dd><p>silence all warnings within this <code class="docutils literal notranslate"><span class="pre">with</span></code>
statement with this class</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.LayerNormStyle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">LayerNormStyle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.LayerNormStyle" title="Permalink to this definition"></a></dt>
<dd><p>The style of layer normalization.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.PoolerType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">PoolerType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.PoolerType" title="Permalink to this definition"></a></dt>
<dd><p>An enumeration.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.autoreload_if_notebook">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">autoreload_if_notebook</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#gdeep.utility.autoreload_if_notebook" title="Permalink to this definition"></a></dt>
<dd><p>Autoreload the modules if the environment is a notebook</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.ensemble_wrapper">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">ensemble_wrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">clss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.ensemble_wrapper" title="Permalink to this definition"></a></dt>
<dd><p>function to wrap the ensemble estimators
of the <code class="docutils literal notranslate"><span class="pre">torchensemble</span></code> library.</p>
<p>The only argument is the estimator class. Then
you can initialise the output of this function
as you would normally do for the original
<code class="docutils literal notranslate"><span class="pre">torchensemble</span></code> class</p>
<dl class="simple">
<dt>Args</dt><dd><dl class="simple">
<dt>clss:</dt><dd><p>the class of the estimator, like
<code class="docutils literal notranslate"><span class="pre">VotingClassifier</span></code> for example</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>type:</dt><dd><p>the initialised ensemble estimator
class that is compatible with giotto-deep</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.get_parameter_types">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">get_parameter_types</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#gdeep.utility.get_parameter_types" title="Permalink to this definition"></a></dt>
<dd><p>Returns a list of the types of the parameters of a function.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func: The function to get the types of the parameters of.</p>
</dd>
<dt>Returns:</dt><dd><p>A list of the types of the parameters of the function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.get_return_type">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">get_return_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="headerlink" href="#gdeep.utility.get_return_type" title="Permalink to this definition"></a></dt>
<dd><p>Returns the type of the return value of a function.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func: The function to get the type of the return value of.</p>
</dd>
<dt>Returns:</dt><dd><p>The type of the return value of the function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.is_notebook">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">is_notebook</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#gdeep.utility.is_notebook" title="Permalink to this definition"></a></dt>
<dd><p>Check if the current environment is a notebook</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="simple">
<dt>bool:</dt><dd><p>True if the environment is a notebook, False otherwise</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.save_model_and_optimizer">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">save_model_and_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trial_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store_pickle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.save_model_and_optimizer" title="Permalink to this definition"></a></dt>
<dd><p>Save the model and the optimizer state_dict</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>model (nn.Module):</dt><dd><p>the model to be saved</p>
</dd>
<dt>model_name (str):</dt><dd><p>model name</p>
</dd>
<dt>trial_id (str):</dt><dd><p>trial id to add to the name</p>
</dd>
<dt>optimizer (torch.optim):</dt><dd><p>the optimizer to save</p>
</dd>
<dt>store_pickle (bool, default False):</dt><dd><p>whether to store the pickle file of the model
instead of the state_dict. The default
is for state_dicts</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.torch_transform">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.</span></span><span class="sig-name descname"><span class="pre">torch_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#gdeep.utility.torch_transform" title="Permalink to this definition"></a></dt>
<dd><p>Transforms a numpy array transform to a torch transform.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>transform: Either a callable that takes a numpy array and returns a</dt><dd><p>numpy array or a callable that takes a tensor and returns a tensor.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>The torch transform.</p>
</dd>
</dl>
</dd></dl>

<section id="module-gdeep.utility.optimization">
<span id="persistence-gradient"></span><h2>Persistence Gradient<a class="headerlink" href="#module-gdeep.utility.optimization" title="Permalink to this heading"></a></h2>
<dl class="py exception">
<dt class="sig sig-object py" id="gdeep.utility.optimization.MissingClosureError">
<em class="property"><span class="pre">exception</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.optimization.</span></span><span class="sig-name descname"><span class="pre">MissingClosureError</span></span><a class="headerlink" href="#gdeep.utility.optimization.MissingClosureError" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.optimization.PersistenceGradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.optimization.</span></span><span class="sig-name descname"><span class="pre">PersistenceGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">homology_dimensions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zeta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collapse_edges</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_edge_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">inf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_digits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'euclidean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.optimization.PersistenceGradient" title="Permalink to this definition"></a></dt>
<dd><p>This class computes the gradient of the persistence
diagram with respect to a point cloud. The algorithms has
first been developed in <a class="reference external" href="https://arxiv.org/abs/2010.08356">https://arxiv.org/abs/2010.08356</a> .</p>
<p>Disclaimer: this algorithm works well for generic point clouds.
In case your point cloud has many simplices with same
filtration values, the matching of the points to the persistent
features may fail to disambiguate.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>zeta :</dt><dd><p>the relative weight of the regularisation part
of the <code class="docutils literal notranslate"><span class="pre">persistence_function</span></code></p>
</dd>
<dt>homology_dimensions :</dt><dd><p>tuple of homology dimensions</p>
</dd>
<dt>collapse_edges :</dt><dd><p>whether to use Collapse or not. Not implemented yet.</p>
</dd>
<dt>max_edge_length :</dt><dd><p>the maximum edge length
to be consider not infinity</p>
</dd>
<dt>approx_digits :</dt><dd><p>digits after which to trunc floats for
list comparison</p>
</dd>
<dt>metric :</dt><dd><p>either <code class="docutils literal notranslate"><span class="pre">&quot;euclidean&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;precomputed&quot;</span></code>.
The second one is in case of <code class="docutils literal notranslate"><span class="pre">x</span></code> being
the pairwise-distance matrix or
the adjacency matrix of a graph.</p>
</dd>
<dt>directed :</dt><dd><p>whether the input graph is a directed graph
or not. Relevant only if <code class="docutils literal notranslate"><span class="pre">metric</span> <span class="pre">=</span> <span class="pre">&quot;precomputed&quot;</span></code></p>
</dd>
</dl>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gdeep.utility.optimization</span> <span class="kn">import</span> <span class="n">PersistenceGradient</span>
<span class="c1"># prepare the datum</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="c1"># select the homology dimensions</span>
<span class="n">hom_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="c1"># initialise the class</span>
<span class="n">pg</span> <span class="o">=</span> <span class="n">PersistenceGradient</span><span class="p">(</span><span class="n">homology_dimensions</span><span class="o">=</span><span class="n">hom_dim</span><span class="p">,</span>
                         <span class="n">zeta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                         <span class="n">max_edge_length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                         <span class="n">collapse_edges</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># run the optimisation for four epochs!</span>
<span class="n">pg</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="gdeep.utility.optimization.PersistenceGradient.persistence_function">
<span class="sig-name descname"><span class="pre">persistence_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#gdeep.utility.optimization.PersistenceGradient.persistence_function" title="Permalink to this definition"></a></dt>
<dd><p>This is the Loss function to optimise.
<span class="math notranslate nohighlight">\(L=-\sum_i^p |\epsilon_{i2}-\epsilon_{i1}|+
\lambda \sum_{x \in X} ||x||_2^2\)</span>
It is composed of a regularisation term and a
function on the filtration values that is (p,q)-permutation
invariant.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>xx:</dt><dd><p>this is the persistence function argument, a tensor</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>Tensor:</dt><dd><p>the function value at <code class="docutils literal notranslate"><span class="pre">xx</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gdeep.utility.optimization.PersistenceGradient.phi">
<span class="sig-name descname"><span class="pre">phi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#gdeep.utility.optimization.PersistenceGradient.phi" title="Permalink to this definition"></a></dt>
<dd><p>This function is from <span class="math notranslate nohighlight">\((R^d)^n\)</span> to <span class="math notranslate nohighlight">\(R^{|K|}\)</span>,
where K is the top simplicial complex of the VR filtration.
It is defined as:
<span class="math notranslate nohighlight">\(\Phi_{\sigma}(X)=max_{i,j \in \sigma}||x_i-x_j||.\)</span></p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>x:</dt><dd><p>the argument of <span class="math notranslate nohighlight">\(\Phi\)</span>, a tensor</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>Tensor:</dt><dd><p>the value of <span class="math notranslate nohighlight">\(\Phi\)</span> at <code class="docutils literal notranslate"><span class="pre">x</span></code></p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gdeep.utility.optimization.PersistenceGradient.powerset">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">powerset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">[1,2,3])</span> <span class="pre">--&gt;</span> <span class="pre">()</span> <span class="pre">(1,)</span> <span class="pre">(2,)</span> <span class="pre">(3,)</span> <span class="pre">(1,2)</span> <span class="pre">(1,3)</span> <span class="pre">(2,3)</span> <span class="pre">(1,2,3</span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.optimization.PersistenceGradient.powerset" title="Permalink to this definition"></a></dt>
<dd><p>up to <cite>max_length</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gdeep.utility.optimization.PersistenceGradient.sgd">
<span class="sig-name descname"><span class="pre">sgd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Figure</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Figure</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#gdeep.utility.optimization.PersistenceGradient.sgd" title="Permalink to this definition"></a></dt>
<dd><p>This function is the core function of this class and uses the
SGD method to move points around in order to optimise
<code class="docutils literal notranslate"><span class="pre">persistence_function</span></code></p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>xx:</dt><dd><p>2d tensor representing the point cloud,
the first dimension is <code class="docutils literal notranslate"><span class="pre">n_points</span></code> while the second
<code class="docutils literal notranslate"><span class="pre">n_features</span></code></p>
</dd>
<dt>lr:</dt><dd><p>learning rate for the SGD</p>
</dd>
<dt>n_epochs:</dt><dd><p>the number of gradient iterations</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>fig, fig3d, loss_val:</dt><dd><p>respectively the plotly <code class="docutils literal notranslate"><span class="pre">quiver_plot</span></code>, plotly <code class="docutils literal notranslate"><span class="pre">cone_plot</span></code>
adds the list of loss function values over the epochs</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.optimization.SAM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.optimization.</span></span><span class="sig-name descname"><span class="pre">SAM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.optimization.SAM" title="Permalink to this definition"></a></dt>
<dd><dl class="py method">
<dt class="sig sig-object py" id="gdeep.utility.optimization.SAM.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.optimization.SAM.step" title="Permalink to this definition"></a></dt>
<dd><p>Performs a single optimization step (parameter update).</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>closure (callable): A closure that reevaluates the model and</dt><dd><p>returns the loss. Optional for most optimizers.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unless otherwise specified, this function should not modify the
<code class="docutils literal notranslate"><span class="pre">.grad</span></code> field of the parameters.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gdeep.utility.optimization.SAMOptimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gdeep.utility.optimization.</span></span><span class="sig-name descname"><span class="pre">SAMOptimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gdeep.utility.optimization.SAMOptimizer" title="Permalink to this definition"></a></dt>
<dd><p>This is the class to be used in the pipeline.</p>
<p>First you need to initialise this class
with the torch optimiser
that you would like to apply SAM to.</p>
<p>Then, at the following call, the instance
behaves extcly like the SAM optimiser</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>optimizer (torch.optim):</dt><dd><p>the optimiser class (not the instance)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-gdeep.utility.extended_persistence">
<span id="extended-persistence"></span><h2>Extended Persistence<a class="headerlink" href="#module-gdeep.utility.extended_persistence" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="gdeep.utility.extended_persistence.graph_extended_persistence_hks">
<span class="sig-prename descclassname"><span class="pre">gdeep.utility.extended_persistence.</span></span><span class="sig-name descname"><span class="pre">graph_extended_persistence_hks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adj_mat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diffusion_parameter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="data.html#gdeep.data.persistence_diagrams.OneHotEncodedPersistenceDiagram" title="gdeep.data.persistence_diagrams.one_hot_persistence_diagram.OneHotEncodedPersistenceDiagram"><span class="pre">OneHotEncodedPersistenceDiagram</span></a></span></span><a class="headerlink" href="#gdeep.utility.extended_persistence.graph_extended_persistence_hks" title="Permalink to this definition"></a></dt>
<dd><p>Compute the extended persistence of a graph.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>adj_mat:</dt><dd><p>The adjacency matrix of the graph.</p>
</dd>
<dt>diffusion_parameter:</dt><dd><p>The diffusion parameter of the heat kernel.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>ndarray:</dt><dd><p>The extended persistence of the graph.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="topology_layers.html" class="btn btn-neutral float-left" title="Topology Layers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, L2F SA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>