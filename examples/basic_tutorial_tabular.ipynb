{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tutorial: tabular data\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "This short tutorial provides you with the basic functioning of *giotto-deep* API. As an example, we take a simple classification problem in which we have a point cloud representing two entangled tori.\n",
    "\n",
    "## Scope\n",
    "\n",
    "The goal of this problem is to build a simple feed-forward neural network that is able to separate the two point clouds. The topology of the dataset is non trivial and we empirically discovered that a minimum number of nodes per layer is required to have a good splitting.\n",
    "\n",
    "## Plan for this tutorial\n",
    "\n",
    "The main steps of the tutorial are the following:\n",
    " 1. creation of a dataset\n",
    " 2. creation of a model\n",
    " 3. define metrics and losses\n",
    " 4. run trainig\n",
    " 5. visualise results interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from gtda.diagrams import BettiCurve\n",
    "from gtda.plotting import plot_betti_surfaces\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.utility.optimization import SAMOptimizer\n",
    "from gdeep.visualization import persistence_diagrams_of_activations\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.visualization import Visualiser\n",
    "from gdeep.utility import DEVICE\n",
    "from gdeep.search import GiottoSummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the results of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/exampled` folder. There you can run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training pahse to see all the visualization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = GiottoSummaryWriter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your dataset\n",
    "\n",
    "The dataset consists of two entangled tori and the goal is to classify the points that belong to one or the other torus. Note that the topology of the decision boundary is non trivial!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DatasetBuilder(name=\"DoubleTori\")\n",
    "ds_tr, ds_val, _ = bd.build()\n",
    "\n",
    "dl_builder = DataLoaderBuilder((ds_tr, ds_val))\n",
    "dl_tr, dl_val, dl_ts = dl_builder.build(({\"batch_size\": 23}, {\"batch_size\": 23}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your model\n",
    "\n",
    "In the next few cells we show hoe easy it is in giotto-deep to define a model and start th training: first, let's define the model using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model1, self).__init__()\n",
    "        self.seqmodel = nn.Sequential(nn.Flatten(), FFNet(arch=[3, 5, 10, 5, 2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seqmodel(x)\n",
    "\n",
    "\n",
    "model = model1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we have the model and the data, only a couple of code lines is needed to start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initlaise the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialise the pipelien class\n",
    "pipe = Trainer(\n",
    "    model,\n",
    "    (dl_tr, dl_val),\n",
    "    loss_fn,\n",
    "    writer,\n",
    "    k_fold_class=StratifiedKFold(3, shuffle=True),\n",
    ")\n",
    "\n",
    "# initialise the SAM optimiser\n",
    "Optim = SAMOptimizer(SGD)  # this is a class, not an instance!\n",
    "\n",
    "# train the model with learning rate scheduler and cross-validation\n",
    "pipe.train(Optim, 5, True,\n",
    "           optimizers_param={\"lr\": 0.01},\n",
    "           lr_scheduler=ExponentialLR,\n",
    "           scheduler_params={\"gamma\": 0.9},\n",
    "           profiling=False,\n",
    "           store_grad_layer_hist=True,\n",
    "           writer_tag=\"tori\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Evaluation\n",
    "\n",
    "We can easily evaluate the model performance and compute the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the model performances for the classification task\n",
    "pipe.evaluate_classification(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced topic: add pipeline hooks\n",
    "\n",
    "It is possible to add a hook (a callable) that is called at the end of each training epoch.\n",
    "\n",
    "The arguments of the hook are fix and have to respect the order you see in this example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_of_hook(epoch, optim, me, writer):\n",
    "    print(\n",
    "        f\"Here we print the learning rate {optim.param_groups[0]['lr']} at epoch={epoch}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"We can also get the value of gradients and parameters of the model \"\n",
    "        f\"using the model extractor! {me.get_layers_param():}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# register the hook\n",
    "pipe.register_pipe_hook(example_of_hook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model with cross validation: we just have to set the parameter `cross_validation = True`.\n",
    "\n",
    "The `keep_training = True` flag allow us to restart from the same scheduler, optimiser and trained model obtained at thhe end of the last training in the instance of the class `pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with CV\n",
    "pipe.train(\n",
    "    SGD,\n",
    "    3,\n",
    "    cross_validation=True,\n",
    "    keep_training=True,\n",
    "    profiling=True,\n",
    "    writer_tag=\"tori/kt\",\n",
    ")\n",
    "\n",
    "# since we used the keep training flag, the optimiser has not been modified compared to the previous training.\n",
    "print(pipe.optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply use interpretability tools\n",
    "\n",
    "Eventually, one would like to know why a neural network has made e certain classification choice. Even though the models are complex, there are tools in giotto-deep to help you understand which feature mostly contributed to the network choice.\n",
    "\n",
    "In the next cell we use the various features importance techniques on the model.\n",
    "\n",
    "The output is automatically shipped to the tensorboard, in the image section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpreter(pipe.model)\n",
    "inter.feature_importance(next(iter(dl_tr))[0], y=next(iter(dl_tr))[1], n_steps=50)\n",
    "\n",
    "vs = Visualiser(pipe)\n",
    "plt = vs.plot_feature_importance(inter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise activations and other topological aspects of your model\n",
    "\n",
    "This concluding section shows you how it is possible to visualise a lot of information (both statistical and topological) on your network in one line thanks to giotto-deep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a batch of data\n",
    "x, y = next(iter(dl_tr))[0].to(DEVICE), next(iter(dl_tr))[1].to(DEVICE)\n",
    "\n",
    "# send to tensorboard the model graph!\n",
    "vs.plot_interactive_model()\n",
    "\n",
    "# send to tensorboard the 3d plot of a batch!\n",
    "vs.plot_3d_dataset(n_pts=100)\n",
    "\n",
    "# send to tensorboard the point cloud, whose coordinates are the activations in each layer, corresponding to the batch x\n",
    "vs.plot_activations((x, y))\n",
    "\n",
    "# plot persistence diagrams of the actiivation point clouds\n",
    "vs.plot_persistence_diagrams((x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sampled decision boudnary!\n",
    "vs.plot_decision_boundary(n_epochs=500, precision=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the betti surface of all the activation layers\n",
    "vs.plot_betti_surface_layers((0, 1), x)\n",
    "# plot the betti curves of each activation layers\n",
    "vs.plot_betti_curves_layers((0, 1), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a chosen filtration value, compute the evolution of the betti numbers through the layers\n",
    "fig = vs.plot_betti_numbers_layers(batch=next(iter(dl_tr)), filtration_value=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
