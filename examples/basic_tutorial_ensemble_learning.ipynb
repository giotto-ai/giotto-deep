{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2888dd06-cbb6-4a2f-9e0e-ef4ddbbf4b1b",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "It is possible, in giotto-deep, to use the ensemble models of the library `ensemble-pytorch` together with all the functionalities of `gdeep`.\n",
    "\n",
    "## Scope\n",
    "\n",
    "Ensamble technique put together the predictions of different models and decide which is the best answer. It is a bit like having and ensemble of experts giving opinions and then the person in charge takes the final decision. In this example, we will try out the `VotingClassifer`, i.e. an ensemble method that decides on the best preediciton based on the majority of experts votes.\n",
    "\n",
    "## Content\n",
    "These aree the main steps we wll follow:\n",
    " 1. Load your data\n",
    " 2. Defne a single expert\n",
    " 3. wrap the ensemble model\n",
    " 4. train the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb04edc-30ff-4139-b019-4be72040dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim import SGD, Adam\n",
    "from torchensemble import VotingClassifier\n",
    "\n",
    "from gdeep.data.datasets import DatasetBuilder, DataLoaderBuilder\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.utility.optimisation import SAMOptimizer\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.utility import ensemble_wrapper\n",
    "from gdeep.visualisation import Visualiser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df056f-31b3-4ce2-bd08-c7514528803e",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the results of your models, you need to start tensorboard.\n",
    "On the terminal, move inside the `/examples` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training to see all the visualisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaed74-fa14-4d33-82cd-d08802ff4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956ff40-cc51-49bb-bd72-34a05f06ea99",
   "metadata": {},
   "source": [
    "# Load your data\n",
    "\n",
    "In this example we use a tabular dataset and the task is a classification task. The dataset is a point cloud representing two entangled tori and the model needs to classify each point as belonging to one or the other torus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ebf3f-24ed-4b75-8532-bae01dbbb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DatasetBuilder(name=\"DoubleTori\")\n",
    "ds_tr, ds_val, _ = bd.build()\n",
    "# train_indices = list(range(160))\n",
    "dl = DataLoaderBuilder((ds_tr, ds_val))\n",
    "dl_tr, dl_val, dl_ts = dl.build(({\"batch_size\": 23}, {\"batch_size\": 23}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb7142-062c-452f-af3d-924b879d4dbb",
   "metadata": {},
   "source": [
    "# Define a single estimator of the ensemble\n",
    "\n",
    "You can define a single estimator of an ensemble as you would normally do with any other neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21393c6-2ea2-48f4-bf81-7954dc1fa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple model\n",
    "class model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model1, self).__init__()\n",
    "        self.seqmodel = nn.Sequential(nn.Flatten(), FFNet(arch=[3, 7, 7, 2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seqmodel(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f44567-49ab-4153-bce4-c09f0d4b3926",
   "metadata": {},
   "source": [
    "# Wrap the ensamble models\n",
    "\n",
    "You can wrap the ensamble-pytorch models with the utiliy function `ensemble_wrapper`. Here below the concrete example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5aea8-3a74-4954-adae-8b40390c1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble_wrapper(VotingClassifier)(\n",
    "    estimator=model1, n_estimators=10, cuda=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8167e-9b7b-43a4-9b2b-9b28b303def4",
   "metadata": {},
   "source": [
    "What you would have done instead, renouncing to many giotto-deep capablities:\n",
    "\n",
    "```\n",
    "model = VotingClassifier(\n",
    "    estimator=model1,\n",
    "    n_estimators=10,\n",
    "    cuda=False\n",
    ")\n",
    "model.set_optimizer(\"Adam\")\n",
    "model.fit(train_loader=dl_tr,epochs=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d96a5-8de4-4d2d-8048-dcc0e8a2bed2",
   "metadata": {},
   "source": [
    "# Train your ensemble of models\n",
    "You can easily train your ensemble model as you would train any other model in giotto-deep: initialise the `Trainer` class and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891a7ac-c9e3-4d02-8138-33569fdaa622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlaise the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# initialise the pipelien class\n",
    "pipe = Trainer(model, (dl_tr, dl_ts), loss_fn, writer)\n",
    "\n",
    "# initialise the SAM optimiser\n",
    "optim = SAMOptimizer(SGD)  # this is a class, not an instance!\n",
    "\n",
    "# train the model with learning rate scheduler\n",
    "pipe.train(\n",
    "    optim,\n",
    "    7,\n",
    "    False,\n",
    "    optimizers_param={\"lr\": 0.01},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"ensemble\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67284b-71df-4480-9f7b-ae7d44da6812",
   "metadata": {},
   "source": [
    "# Visualise the model graph\n",
    "\n",
    "You can integractively visualise your ensemble of models by checking it on tensorboard after these few lines are executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fbd97-42bb-4299-b252-7853665164be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise he visualiser\n",
    "vs = Visualiser(pipe)\n",
    "\n",
    "# send the graph of the model to tensorboard\n",
    "vs.plot_data_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d113dd-a654-4887-9ed9-f1c186d836ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}