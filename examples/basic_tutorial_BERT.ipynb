{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921c5234",
   "metadata": {},
   "source": [
    "# Basic Tutorial: BERT Models with *Giotto-Deep* and Topological Pruning\n",
    "\n",
    "#### Author: Henry Kirveslahti\n",
    "\n",
    "In this tutorial we demonstrate how to run a pre-trained BERT model with *Giotto-Deep*, as well as showcase some topological pruning methods. These pruning methods are based on the preprint *https://arxiv.org/pdf/2206.15195.pdf* by I.Perez & R.Reinauer.\n",
    "\n",
    "We will consider the NLP problem of classifying (a subset of) sentences in the *Corpus of Linguistic Acceptability (CoLA)*. To this end, we deploy a pre-trained BERT model from *HuggingFace*. We will construct the attention graph from this model, which we will use to derive Persistent Images. We then create a model that takes these persistent images as an input, and based on this model, we can compute importance scores for each of the attention heads. By only using the attention heads with high score, we can create a pruned model.\n",
    "\n",
    "\n",
    "The tutorial is organized as follows:\n",
    "\n",
    "1. Deploying the HuggingFace Model\n",
    "\n",
    "2. Fine-tuning the model using *Giotto-deep*\n",
    "\n",
    "3. Retrieving the Topological Summaries\n",
    "\n",
    "4. Training a topological model\n",
    "\n",
    "5. Pruning\n",
    "\n",
    "\n",
    "First we import some dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9373c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import wget\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from transformers import (\n",
    "                          BertTokenizer, \n",
    "                          BertForSequenceClassification,\n",
    "                          AdamW,\n",
    "                          BertConfig,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.optim import Adam, SparseAdam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from gdeep.models import FFNet\n",
    "from gdeep.utility import DEVICE\n",
    "from gdeep.trainer import Trainer\n",
    "from gdeep.data import TransformingDataset\n",
    "from gdeep.data.preprocessors import TokenizerTranslation\n",
    "from gdeep.data.datasets import DatasetBuilder, FromArray, DataLoaderBuilder\n",
    "from gdeep.models import ModelExtractor\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.search import GiottoSummaryWriter\n",
    "from gudhi.representations.vector_methods import PersistenceImage as gPI\n",
    "from gudhi import RipsComplex as gRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54449265",
   "metadata": {},
   "source": [
    "# Initialize the tensorboard writer\n",
    "\n",
    "In order to analyse the results of your models, you need to start tensorboard. All data about the model, the training, the hyperparameters... will be stored there.\n",
    "\n",
    "## How to start tensorboard\n",
    "On the terminal, move inside the `/examples` folder. There run the following command:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "Then go [here](http://localhost:6006/) after the training step to visualise all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a44e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = GiottoSummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5bbce",
   "metadata": {},
   "source": [
    "## 1. Deploying the BERT model\n",
    "\n",
    "In this section we'll just download some data and deploy a BERT model from Hugging face. This lengthy part is quite technical and independent of *giotto-deep*, so we'll just need to click through this section to get to Section 2. **The only exception is the variable**\n",
    "```\n",
    "n_sentences_to_consider\n",
    "```\n",
    "**which you could set a bit higher to get more interesting results (at a computational expense).**\n",
    "\n",
    "### 1.1 Preprocessing\n",
    "Following the pre-print, we'll adapt the pre-processing steps from *https://github.com/MohamedAteya/BERT-Fine-Tuning-Sentence-Classification-for-CoLA/blob/master/BERT_Fine_Tuning_Sentence_Classification_for_CoLA.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sentences_to_consider=200\n",
    "# Downloading the data\n",
    "print('Downloading dataset...')\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./cola_public_1.1.zip'):\n",
    "    wget.download(url, './cola_public_1.1.zip')\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "if not os.path.exists('./cola_public/'):\n",
    "    !unzip cola_public_1.1.zip\n",
    "# Load the dataset into a pandas dataframe.\n",
    "tmp_path=os.path.join('./cola_public','raw','in_domain_train.tsv')\n",
    "df = pd.read_csv(tmp_path, delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "sentences=sentences[0:n_sentences_to_consider]\n",
    "labels=labels[0:n_sentences_to_consider]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    encoded_sent = tokenizer.encode( sent, add_special_tokens = True)\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "print('Max length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813d88e",
   "metadata": {},
   "source": [
    "Next we'll define a makeshift preprocessing step. This is a verbatim copy of the padding function from *tensorflow keras*. The point of the padding function is to add extra zeros to the input so that each of them is of the same size. We'll need this for the HuggingFace BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf103c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "def pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=None,\n",
    "    dtype=\"int32\",\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    value=0.0,\n",
    "):\n",
    "    if not hasattr(sequences, \"__len__\"):\n",
    "        raise ValueError(\"`sequences` must be iterable.\")\n",
    "    num_samples = len(sequences)\n",
    "\n",
    "    lengths = []\n",
    "    sample_shape = ()\n",
    "    flag = True\n",
    "    for x in sequences:\n",
    "        try:\n",
    "            lengths.append(len(x))\n",
    "            if flag and len(x):\n",
    "                sample_shape = np.asarray(x).shape[1:]\n",
    "                flag = False\n",
    "        except TypeError as e:\n",
    "            raise ValueError(\n",
    "                \"`sequences` must be a list of iterables. \"\n",
    "                f\"Found non-iterable: {str(x)}\"\n",
    "            ) from e\n",
    "\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(\n",
    "        dtype, np.unicode_\n",
    "    )\n",
    "    if isinstance(value, str) and dtype != object and not is_dtype_str:\n",
    "        raise ValueError(\n",
    "            f\"`dtype` {dtype} is not compatible with `value`'s type: \"\n",
    "            f\"{type(value)}\\nYou should set `dtype=object` for variable length \"\n",
    "            \"strings.\"\n",
    "        )\n",
    "\n",
    "    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == \"pre\":\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == \"post\":\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError(f'Truncating type \"{truncating}\" not understood')\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError(\n",
    "                f\"Shape of sample {trunc.shape[1:]} of sequence at \"\n",
    "                f\"position {idx} is different from expected shape \"\n",
    "                f\"{sample_shape}\"\n",
    "            )\n",
    "\n",
    "        if padding == \"post\":\n",
    "            x[idx, : len(trunc)] = trunc\n",
    "        elif padding == \"pre\":\n",
    "            x[idx, -len(trunc) :] = trunc\n",
    "        else:\n",
    "            raise ValueError(f'Padding type \"{padding}\" not understood')\n",
    "    return x\n",
    "\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data to train and validation sets\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=13, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 2,\n",
    "    output_attentions = True, \n",
    "    output_hidden_states = False\n",
    ")\n",
    "\n",
    "if(device.type=='cuda'):\n",
    "    model.cuda()\n",
    "if(device.type=='cpu'):\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273ad8",
   "metadata": {},
   "source": [
    "## 2. Fine-Tuning the Model with *Giotto-Deep*\n",
    "\n",
    "To train a model with *giotto-deep* we'll need a) data, b) loss function, and optionally c) a performance metric. We define these below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder = DataLoaderBuilder((FromArray(train_inputs, train_labels), \\\n",
    "                                FromArray(validation_inputs, validation_labels)))\n",
    "dl_tr, dl_val, _ = dl_builder.build(({\"batch_size\": 8}, {\"batch_size\": 8}))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5bdfd",
   "metadata": {},
   "source": [
    "As per the usual *giotto-deep* paradigm, we pass these to the Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Trainer(model, (dl_tr, dl_val), loss, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581779e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with learning rate scheduler\n",
    "pipe.train(\n",
    "    Adam,\n",
    "    4,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf81c2",
   "metadata": {},
   "source": [
    "## 3. Retrieving the topological summaries\n",
    "\n",
    "Now that we have trained our model and fine-tuned it, we would like to extract the topological summaries. For now we'll be interested in the attention matrices. We can retrieve them with the Model Extractor. Before diving deep into the attention matrices, let us first take a look at the inner workings of our HuggingFace model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee651a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = ModelExtractor(pipe.model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Layers\n",
    "layer_names = ex.get_layers_param().keys()\n",
    "for tmp,layer in enumerate(layer_names):\n",
    "    print(tmp,layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a6907",
   "metadata": {},
   "source": [
    "Next we will compute the attention masks. The point of the attention masks is that not all the sentences contain the same number of words, (nor tokenized words). The attention masks records the dummy binary variables indicating which of the elements of the padded inputs are actual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for computing attention masks\n",
    "def attention_mask_from_input(input):\n",
    "    mask=torch.zeros(input.shape)\n",
    "    mask[torch.nonzero(input, as_tuple=True)]=1\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8265b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we'll look into the sizes of the different layers.\n",
    "tmp,batch=next(enumerate(dl_tr))\n",
    "b_input_ids = batch[0].to(device)\n",
    "b_input_mask=attention_mask_from_input(b_input_ids)\n",
    "b_labels = batch[1].to(device)\n",
    "outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "layers = ex.get_activations(b_input_ids)\n",
    "for ind_k,layer in enumerate(layers):\n",
    "    print(ind_k,layer[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19be50",
   "metadata": {},
   "source": [
    "From the above we see that the attention matrices are in the layers with indices 9,27,45,63,81,99,117,135,153,171,189,207. These corresponds to the Multi-head attention layers at different depths. Each of these contains 12 attention heads. Next we'll loop over the train data and store these layers, with the ultimate goal of constructing the Persistent images for each.\n",
    "\n",
    "### 3.1. The Attention Matrices\n",
    "\n",
    "We will get an attention matrix for each combination of the 144 (12x12) attention heads and $n$ sentences (that is, $144n$ matrices). \n",
    "\n",
    "For the persistence function, we are using the mean aggregation scheme, which means that the only data that we need is the mean of the attention scores of edges $e_{i,j}$ and $e_{j,i}$ (and of course the vertex birth times, which are all 0). These are obtained conveniently via matrix transpose. In the code snippet below this is achieved with\n",
    "\n",
    "```\n",
    "aggregated_attention=0.5*(raw_attention+raw_attention.transpose(0,1,3,2))\n",
    "```\n",
    "\n",
    "Note that in the stored attention matrices, the first index runs over $L$ (layers of the network) and the second over $H$ (heads in a fixed layer). The last two indices are, of course, for the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for computing attention matrices.\n",
    "# In: a giotto-dataset returned by DataLoaderBuilder.build\n",
    "# Out: 1) all_the_attention: A list of stacked attention matrices, one for each sample in the dataset\n",
    "#         Each stack is of size (12,12,n_i,n_i),\n",
    "#         where n_i is the length of the sentence (measured in number of tokens)\n",
    "#         The attention matrices are already mean-aggregated\n",
    "#      2) all_the_labels: The label associated with the sentences\n",
    "#      3) raw_attentions: The raw attention matrices. Same shape as all_the_attention\n",
    "#         Used only for plotting\n",
    "def compute_attention_matrices(dataset):\n",
    "    all_the_attention=[]\n",
    "    all_the_labels=[]\n",
    "    raw_attentions=[]\n",
    "    klist=[9,27,45,63,81,99,117,135,153,171,189,207]\n",
    "    for _,batch in enumerate(dataset):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask=attention_mask_from_input(b_input_ids)\n",
    "        b_labels = batch[1].to(device)\n",
    "        layer_activations = ex.get_activations(b_input_ids)\n",
    "        for i in range(len(batch[0])):\n",
    "            keepers=np.where(b_input_mask[i]>0)\n",
    "            tmp2=keepers[0]\n",
    "            raw_attention=np.zeros((12,12,len(tmp2),len(tmp2)))\n",
    "            for ind_k,k in enumerate(klist):\n",
    "                tmp=layer_activations[k][i].detach().numpy()\n",
    "                tmp3=tmp[:,tmp2,:] # subset with the attention mask\n",
    "                raw_attention[ind_k,:,:,:]=tmp3[:,:,tmp2] #subset with the attention mask\n",
    "            aggregated_attention=0.5*(raw_attention+raw_attention.transpose(0,1,3,2))\n",
    "            raw_attentions.append(raw_attention)\n",
    "            all_the_attention.append(aggregated_attention)\n",
    "            all_the_labels.append(b_labels[i])\n",
    "    return(all_the_attention,all_the_labels,raw_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_attention_T, all_the_labels_T, raw_attentions_T = compute_attention_matrices(dl_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32dcc4",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Below we plot some of the attention matrices. First the raw attention matrices, then the mean aggregated ones. We'll plot these as an example, so we can later see what kind of persistent diagrams/ images these matrices produce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a09c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw attention matrices for the last training sentence:\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Raw Attention Matrices')\n",
    "\n",
    "for i in range(raw_attentions_T[-1].shape[0]):\n",
    "    for j in range(raw_attentions_T[-1].shape[1]):\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].imshow(raw_attentions_T[-1][i,j,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aeb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean aggregated attention matrices for the last training sentence:\n",
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Mean Aggregated Matrices')\n",
    "\n",
    "for i in range(all_the_attention_T[-1].shape[0]):\n",
    "    for j in range(all_the_attention_T[-1].shape[1]):\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].imshow(all_the_attention_T[-1][i,j,:,:], cmap='hot', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute the attention matrices for the validation set\n",
    "# We will not be needing the raw attention matrices for the validation set\n",
    "all_the_attention_V, all_the_labels_V,_ = compute_attention_matrices(dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5deff10",
   "metadata": {},
   "source": [
    "### 3.2 Persistence Diagrams\n",
    "\n",
    "Next we'll compute the Persistent diagrams. We'll use *gudhi* library for this. The specifications are as in the preprint:\n",
    "1. The filtration value for the undirected edge $(i,j)$ is $1-f(e_{ij},e_{ji})$, where $f$ is the mean of directed edges (See Section 3.2)\n",
    "2. All the vertices are born at 0; (That is: ```np.fill_diagonal(dm,0)```)\n",
    "3. All the essential features are set to die at 1; (```d0[np.isinf(d0)] = 1; d1[np.isinf(d1)] = 1```)\n",
    "4. The maximum dimension is 1. (```max_dimension=1; persistence_dim_max=True)```)\n",
    "\n",
    "See Figure 3 in the preprint for illustrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063cc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for computing persistence diagrams from mean aggregated attention matrices\n",
    "# In: 1) list_of_attention_matrices: A list of attention matrices (as returned by compute_attention_matrices)\n",
    "#     2) Optional: threshold: a lowerbound for the persistent features to be computed\n",
    "#     (Any feature whose persistence (i.e. d-b) is lower than the threshold will be ignored)\n",
    "#     (Setting threshold to -1.0 returns all features regardless of their persistence)\n",
    "# Out: Two lists of persistence diagrams, one for each homology dimension\n",
    "#      These are unpacked lists, meaning that\n",
    "#      the first 144 entries correspond to the first sentence, the next 144 to the next one and so on.\n",
    "#      The fist 12 entries are for the Attention heads from the first layer (L=0),\n",
    "#      and after that the second layer and so on all the way until 144 after which we go to the next sentece.\n",
    "def persistence_diagrams_from_list_attention_matrix(list_of_attention_matrices,threshold=0.0001):\n",
    "    diagramsh0=[]\n",
    "    diagramsh1=[]\n",
    "    for i in range(len(list_of_attention_matrices)):\n",
    "        graph=list_of_attention_matrices[i] # Pick a sentence\n",
    "        for j in range(graph.shape[0]): # Loop over L\n",
    "            for k in range(graph.shape[1]): # Loop over H\n",
    "                dm=1-graph[j,k,:,:] # The filtration value for edges is 1- f(e_i,e_j)\n",
    "                np.fill_diagonal(dm,0) # Set the vertices to be born at 0\n",
    "                gudhiC=gRC(distance_matrix=dm)\n",
    "                simplex_tree = gudhiC.create_simplex_tree(max_dimension=1)\n",
    "                diag = simplex_tree.persistence(min_persistence=threshold,persistence_dim_max=True)\n",
    "                d0=simplex_tree.persistence_intervals_in_dimension(0)\n",
    "                d1=simplex_tree.persistence_intervals_in_dimension(1)\n",
    "                d0[np.isinf(d0)] = 1 # Set H_0 essential features to die at 1\n",
    "                d1[np.isinf(d1)] = 1 # Set H_1 essential features to die at 1\n",
    "                diagramsh0.append(d0)\n",
    "                diagramsh1.append(d1)\n",
    "    return(diagramsh0,diagramsh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above function to compute the persistence diagrams\n",
    "diagramsh0_train,diagramsh1_train=persistence_diagrams_from_list_attention_matrix(all_the_attention_T)\n",
    "diagramsh0_valid,diagramsh1_valid=persistence_diagrams_from_list_attention_matrix(all_the_attention_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb8d75",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Let's plot the Persistent diagrams for the attention matrices we checked earlier. Here we plot all the 144 diagrams: As such they are quite difficult to read. Because these change from run to run, you should hand pick some for closer inspection. Take a look at the matrices above, select a few that look different and look at the corresponding diagrams to get intuition how the diagrams turn out to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last 144 persistent diagrams, corresponding to the last sentence\n",
    "tmp_d0=diagramsh0_train[-144:]\n",
    "tmp_d1=diagramsh1_train[-144:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Persistence Diagrams')\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        ind=12*i+j\n",
    "        axs[i,j].axis('off')\n",
    "        axs[i,j].scatter(tmp_d0[ind][:,0],tmp_d0[ind][:,1],c='blue', s=0.01)\n",
    "        axs[i,j].scatter(tmp_d1[ind][:,0],tmp_d1[ind][:,1],c='red', s=0.01)\n",
    "        line = mlines.Line2D([0, 1], [0, 1], color='black', linewidth=0.05)\n",
    "        axs[i,j].add_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4080f4",
   "metadata": {},
   "source": [
    "### 3.3 Persistent Images\n",
    "\n",
    "We can now compute the Persistent Images. The parameters are adapted from the preprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers0=gPI(bandwidth=0.1, weight=lambda x: 1,im_range=[0,0.01,0,1], resolution=[5,50])\n",
    "PI0t=pers0.fit_transform(diagramsh0_train)\n",
    "PI0v=pers0.fit_transform(diagramsh0_valid)\n",
    "pers1=gPI(bandwidth=0.1, weight=lambda x: 1,im_range=[0,1,0.99,1], resolution=[50,5])\n",
    "PI1t=pers1.fit_transform(diagramsh1_train)\n",
    "PI1v=pers1.fit_transform(diagramsh1_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10529627",
   "metadata": {},
   "source": [
    "The data from the persistent Image computations is a list, which is not fantastic for bookkeeping. We'll convert the data into proper images of size 5x50 with 288 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06301e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper funcion for formatting the persistence images as proper images\n",
    "# In: H0 (An array of persistence images for H0 as returned by fit_transform\n",
    "#         of size (n x 144, 250)), where n is the sample size (number of sentences)\n",
    "#     H1 (An array of persistence images for H1 as returned by fit_transform\n",
    "#         of size (n x 144, 250))\n",
    "# Out: an array of size (n,288,50,5)\n",
    "#      the second dimension is the attention heads concatenated with homology dimension\n",
    "#      This is the same setup as in the preprint, and allows for a direct application of\n",
    "#      a convolutional neural network\n",
    "#      (note that the simple model in this notebook doesn't make use of this structure)\n",
    "\n",
    "def reshape_persistence_images(H0,H1):\n",
    "    H0_reshaped=H0.reshape(-1,144,250)\n",
    "    H0_reshaped=H0_reshaped.reshape(-1,144,50,5)\n",
    "    H0_reshaped=H0_reshaped.transpose(0,1,3,2)\n",
    "    H1_reshaped=H1.reshape(-1,144,250)\n",
    "    H1_reshaped=H1_reshaped.reshape(-1,144,50,5)\n",
    "    H1_reshaped=H1_reshaped.transpose(0,1,3,2)\n",
    "    stack=np.concatenate([H0_reshaped,H1_reshaped],axis=1)\n",
    "    return(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc073fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of transparency (and visualization), we'll reshape our Persistent Images:\n",
    "images_train=reshape_persistence_images(PI0t,PI1t)\n",
    "images_val=reshape_persistence_images(PI0v,PI1v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8284f7",
   "metadata": {},
   "source": [
    "### Some Sanity Checks\n",
    "Let's have a look at the persistent images for the matrices we saw earlier. Again, you should investigate a specific image to get a better idea of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again we pick the last sentence from the train dataset\n",
    "tmp_im0=images_train[-1,:144,:,:] #H0\n",
    "tmp_im1=images_train[-1,144:,:,:] #H1\n",
    "tmp_im0=tmp_im0.transpose(0,2,1)\n",
    "tmp_im1=tmp_im1.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Images H0')\n",
    "\n",
    "for k in range(tmp_im0.shape[0]):\n",
    "    j=math.floor(k/12)\n",
    "    i=k%12\n",
    "    axs[i,j].axis('off')\n",
    "    axs[i,j].imshow(tmp_im0[k,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca81e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(12,12)\n",
    "fig.suptitle('Images H1')\n",
    "\n",
    "for k in range(tmp_im1.shape[0]):\n",
    "    j=math.floor(k/12)\n",
    "    i=k%12\n",
    "    axs[i,j].axis('off')\n",
    "    axs[i,j].imshow(tmp_im1[k,:,:], cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fb675",
   "metadata": {},
   "source": [
    "### A hand-picked example\n",
    "Here we look at a specific example coming from the 4th attention head (H=3) on the 1st (L=0) Multi-Head attention layer. We'll plot the Raw attention matrix, the mean aggregated one as well as the persistent diagram and persistent images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=0\n",
    "H=3\n",
    "k=12*L+H\n",
    "\n",
    "plt.imshow(raw_attentions_T[-1][L,H,:,:], cmap='hot', interpolation='nearest')\n",
    "plt.title(\"Raw Attention Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(all_the_attention_T[-1][L,H,:,:], cmap='hot', interpolation='nearest')\n",
    "plt.title(\"The Mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The persistent diagram from the matrix above:\n",
    "h0plot=plt.scatter(tmp_d0[k][:,0],tmp_d0[k][:,1],c='blue', s=3)\n",
    "h1plot=plt.scatter(tmp_d1[k][:,0],tmp_d1[k][:,1],c='red', s=3)\n",
    "plt.plot([0, 1], c='black')\n",
    "plt.legend((h0plot,h1plot),\n",
    "           ('H_0', 'H_1'),\n",
    "           scatterpoints=3,\n",
    "           loc='lower right',\n",
    "           ncol=2,\n",
    "           fontsize=12)\n",
    "plt.title(\"Resulting Persistent Diagram\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.suptitle(\"Persistent Images\")\n",
    "axs[0].imshow(tmp_im0[k,:,:], cmap='hot', interpolation='nearest')\n",
    "axs[0].title.set_text('H_0')\n",
    "axs[1].imshow(tmp_im1[k,:,:], cmap='hot', interpolation='nearest')\n",
    "axs[1].title.set_text('H_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5183526",
   "metadata": {},
   "source": [
    "## 4. Training a topological model\n",
    "We'll train a super simple model based on our topological summaries. This follows the usual *giotto-deep* recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fa546",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder2 = DataLoaderBuilder((FromArray(images_train, train_labels), FromArray(images_val, validation_labels)))\n",
    "dl_tr2, dl_val2, _ = dl_builder2.build(({\"batch_size\": 8}, {\"batch_size\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c450076",
   "metadata": {},
   "source": [
    "Our model is just a one layer linear model mapping from $\\mathbb{R}^{(288x50x5)}$ to $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(288*50*5,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.000067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Trainer(net, (dl_tr2, dl_val2), criterion, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.train(\n",
    "    Adam,\n",
    "    20,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af94eb4",
   "metadata": {},
   "source": [
    "## 5. Pruning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2400bf6",
   "metadata": {},
   "source": [
    "Compared to the complicated BERT model, the topological model we just defined is quite transparent in that we can easily define importance metrics for the attention heads.\n",
    "\n",
    "One way to do this is to do what was done in the preprint (See Section 6 therein). This is exactly what we do here.\n",
    "\n",
    "We compute the gradient of the output logits with respect to the input image, that is, a stack of persistent image of pixels arranged in an array of size $(288,50,5)$. The gradient is of the same size $(288,50,5)$ and it measures how much the response changes as we change the values of the pixels. If the grad is low in absolute value, changing it would not affect the final classification by much. This the said pixel does not help much in the classification task, the prediction is would be similar regardless of what the actual value was.\n",
    "\n",
    "As we are only interested how the response changes with respect to each attention heads, we need to aggregate the gradients over a) The homology dimension $H_0$ and $H_1$ b) the pixel values $(50,5)$. We can do this by summing over the values (this is equivalent to taking the mean, as each head is summed over $nx2x50x5$ values, where $n$ is the number of sentences considered.\n",
    "\n",
    "We do this as follows:\n",
    "1. compute the gradient of the output logits with respect to the input image for $n$ many sentences\n",
    "2. For each attention head $i$, $i=1,2,\\ldots, 144$, compute the sum over the $nx2x50x5$ many values\n",
    "\n",
    "\n",
    "First we need to format our data to compute the gradient. This is the content of the next code chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1=torch.FloatTensor(images_train)\n",
    "train_labels=torch.FloatTensor(train_labels)\n",
    "validation_labels=torch.FloatTensor(validation_labels)\n",
    "train_labels = train_labels.type(torch.LongTensor)\n",
    "validation_labels = validation_labels.type(torch.LongTensor)\n",
    "batch_size=3\n",
    "tmp2=torch.FloatTensor(images_val)\n",
    "tmp2.requires_grad=True\n",
    "ds1 = TensorDataset(tmp1, train_labels)\n",
    "ds2 = TensorDataset(tmp2, validation_labels)\n",
    "trainloader = torch.utils.data.DataLoader(ds1, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(ds2, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Here we compute the gradients for the first 500 images in our training dataset.\n",
    "imageset=trainloader.dataset[0:500][0]\n",
    "target_label=trainloader.dataset[0:500][1]\n",
    "a = torch.autograd.Variable(imageset)\n",
    "a.requires_grad=True\n",
    "outputs=net(a)\n",
    "target_label\n",
    "loss = criterion(outputs,target_label)\n",
    "a_grad = torch.autograd.grad(loss, a, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Take the absolute value of the gradients, and sum them over axes\n",
    "# 0 (the samples) and\n",
    "# (2,3) (The actual persistent image pixels)\n",
    "tmp=np.sum(abs(a_grad[0].detach().cpu().numpy()), axis=(0,2,3))\n",
    "# Average over hom.dim (H0+H1) (first 144 are H0, the rest are H1)\n",
    "tmp2=tmp[0:144]+tmp[144:] \n",
    "\n",
    "# Unpack the scores over 144 attention heads to 12 by 12 matrix, corresponding to H and L \n",
    "tmp3=tmp2.reshape(12,12)\n",
    "# Plot the values\n",
    "plt.imshow(tmp3, cmap='hot', interpolation='nearest')\n",
    "plt.ylabel('L (depth)')\n",
    "plt.xlabel('H (attention head)')\n",
    "plt.title('Importance Scores for Attention heads')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48070ab0",
   "metadata": {},
   "source": [
    "We can now select the most impactful however many heads we want. In the code below we take the top 100. We'll stick to the simple model we used earlier, so you only need to change\n",
    "```\n",
    "heads_to_keep\n",
    "```\n",
    "in the code chunk below to select however many heads you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73848873",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_to_keep=100\n",
    "pruned_indices=np.argsort(tmp2)[-heads_to_keep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pruned indices refer to the attention heads. As we stacked the homology H0 and H1,\n",
    "# the indices for attention head i are\n",
    "#                           i for H0 and\n",
    "#                           (i+144) for H1)\n",
    "pt=np.concatenate((pruned_indices,pruned_indices+144),axis=0)\n",
    "images_train=images_train[:,pt,:,:]\n",
    "images_val=images_val[:,pt,:,:]\n",
    "images_train= images_train.astype(np.float32)\n",
    "images_val= images_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_builder2 = DataLoaderBuilder((FromArray(images_train, train_labels), FromArray(images_val, validation_labels)))\n",
    "dl_tr2, dl_val2, _ = dl_builder2.build(({\"batch_size\": 8}, {\"batch_size\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(2*heads_to_keep*50*5,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(net.parameters(), lr=0.000067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421526f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Trainer(net, (dl_tr2, dl_val2), criterion, writer)\n",
    "# train the model with learning rate scheduler\n",
    "pipe2.train(\n",
    "    Adam,\n",
    "    20,\n",
    "    False,\n",
    "    lr_scheduler=ExponentialLR,\n",
    "    scheduler_params={\"gamma\": 0.9},\n",
    "    profiling=False,\n",
    "    store_grad_layer_hist=True,\n",
    "    writer_tag=\"line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdfa4b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f464b",
   "metadata": {},
   "source": [
    "In this tutorial, we used *giotto-deep* to\n",
    "1. Fit an off the shelf Huggingface model;\n",
    "2. Fine tune it;\n",
    "3. Extract its inner workings to;\n",
    "4. construct a pruned model.\n",
    "\n",
    "Depending on the choices made along the way, the pruned model may be anything from strong to terrible. To increase performance, you may\n",
    "\n",
    "1. Add more data (remember this notebook is heavily subsampled);\n",
    "2. Spend more time fine-tuning the BERT; \n",
    "3. Fit more complicated models;\n",
    "4. Optimize the parameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
