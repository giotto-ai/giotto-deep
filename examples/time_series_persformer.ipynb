{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the topology of signals\n",
    "\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "In this notebook we will give an empirical proof that in some cases the topology, extracted from time-series via Takens embeddings, may contain enough information to discriminate signal from noise.\n",
    "\n",
    "## The dataset\n",
    "\n",
    "The dataset consists of very weak signals in a very noisy background.\n",
    "\n",
    "## The procedure\n",
    "\n",
    "The procedure does not aim at building a classifier, but rather make sure that there is enough information in the topology to distinguish between signals and noise.\n",
    "Ideally, if we were able to overfit the data, we would know that there is enough information in the topology to make the classification. \n",
    "There is only one reasonable tool that can try to overfit our data: `Persformer` (see [here](https://arxiv.org/abs/2112.15210) for more details).\n",
    "\n",
    "### The task\n",
    "\n",
    "We will train `Persformer` and try to overfit the data. The task is a binary classification task: noise VS signal. The signal is preprocessed with takens embedding techniques and `giotto-tda` is used to compute the persistece diagrams. These diagrams are then labelled with either `0` or `1`, depending on whether they contain the signal or not.\n",
    "\n",
    "### Use of saliency\n",
    "\n",
    "Afterwards, thanks to the use of **saliency maps**, we would also be able to understand what features in the persistent diagram are relevant for the classification, And consequently build a simple topological classfier that selects the discovered tpological features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependencies\n",
    "\n",
    "Here we import the `giotto-deep` dependencies and a few standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from gdeep.data import PreprocessingPipeline\n",
    "from gdeep.utility import PoolerType\n",
    "from gdeep.data.datasets import PersistenceDiagramFromFiles\n",
    "from gdeep.data.datasets.base_dataloaders import (DataLoaderBuilder,\n",
    "                                                  DataLoaderParamsTuples)\n",
    "from gdeep.data.persistence_diagrams.one_hot_persistence_diagram import (\n",
    "    OneHotEncodedPersistenceDiagram, collate_fn_persistence_diagrams)\n",
    "from gdeep.search.hpo import GiottoSummaryWriter\n",
    "from gdeep.topology_layers import Persformer, PersformerConfig, PersformerWrapper\n",
    "from gdeep.trainer.trainer import Trainer\n",
    "from gdeep.utility.utils import autoreload_if_notebook\n",
    "from gdeep.analysis.interpretability import Interpreter\n",
    "from gdeep.visualization import Visualiser\n",
    "\n",
    "\n",
    "autoreload_if_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "The data will be generated in the next cell: a sinusoid (the signal) will be interspersed in time by white noise, and then white noise will be added to the whole signal. `SNR = 3` in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the sinusoidl signal\n",
    "pure_signal = np.sin(np.linspace(0, 100, num=500))\n",
    "\n",
    "# intersperse with white noise the sinusoids\n",
    "signal_no_noise = np.hstack((pure_signal, 1-2*np.random.rand(600,), pure_signal, 1-2*np.random.rand(400,)))\n",
    "\n",
    "# build the ground truth\n",
    "label = np.hstack((np.ones((500,)), np.zeros((600,)), np.ones((500,)), np.zeros((400,))))\n",
    "\n",
    "# add noise all over the signal\n",
    "noise = 1-2*np.random.rand(signal_no_noise.shape[0],)\n",
    "snr = 3\n",
    "signal = noise + snr*signal_no_noise\n",
    "\n",
    "# plot\n",
    "px.scatter(signal, title = \"Our Signal\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "There are two steps in the preprocessing:\n",
    "\n",
    "### Takens embedding\n",
    "\n",
    "We propose the lagged embedding to build, out of the time series, a point cloud. It is the topology of this point cloud that we would be interested in. More formally, we extract a sequence of vectors in $\\mathbb{R}^{d}$ of the form,\n",
    "$$\n",
    "TD_{d,\\tau} s : \\mathbb{R} \\to \\mathbb{R}^{d}\\,, \\qquad t \\to \n",
    "\\begin{bmatrix}\n",
    "s(t) \\\\\n",
    "s(t + \\tau) \\\\\n",
    "s(t + 2\\tau) \\\\\n",
    "\\vdots \\\\\n",
    "s(t + (d-1)\\tau)\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "where $d$ is the embedding dimension and $\\tau$ is the time delay. The quantity $(d-1)\\tau$ is known as the \\\"window size\\\" and the difference between $t_{i+1}$ and $t_i$ is called the stride.\n",
    "\n",
    "\n",
    "### Vietoris-Rips persistence\n",
    "\n",
    "The overall point cloud is split into a sequence of point clouds: each one will be transformed into a persistence diagram using the Vietoris-Rips filtration. The output, consisting of persistence diagrams, will then form our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takens_embedding(signal, dimension):\n",
    "    \"\"\"this function runs the takens embedding\n",
    "    on a subsampled signal, meaning that there is no stride\n",
    "    at this level.\n",
    "\n",
    "    Args:\n",
    "        signal (np.array):\n",
    "            complex signal\n",
    "        dimension (int):\n",
    "            takens embedding dimension\n",
    "    \"\"\"\n",
    "    length = signal.shape[0]\n",
    "    lista = [signal[i:length - dimension+i] for i in range(dimension)]\n",
    "    return np.vstack(lista).T\n",
    "\n",
    "te_signal = takens_embedding(signal, 6)\n",
    "pts_per_cloud = 25\n",
    "batches = te_signal.shape[0] // pts_per_cloud\n",
    "\n",
    "# split the point cloud (stride = pts_per_cloud)\n",
    "point_clouds = np.split(te_signal[:batches*pts_per_cloud],\n",
    "                        batches,\n",
    "                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialise the class to compute the topology of the point clouds\n",
    "vr = VietorisRipsPersistence(metric=\"euclidean\",\n",
    "                             homology_dimensions=(0, 1),\n",
    "                             collapse_edges=False,\n",
    "                             coeff=2,\n",
    "                             max_edge_length=np.inf,\n",
    "                             infinity_values=None,\n",
    "                             reduced_homology=True,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "# compute the point clouds persistence\n",
    "dgms = vr.fit_transform(point_clouds)\n",
    "label = np.split(label[:batches * pts_per_cloud],\n",
    "                 batches,\n",
    "                 axis=0)\n",
    "\n",
    "# unit test:\n",
    "assert dgms.shape[0] == batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for each diagram\n",
    "actual_labels = np.round(np.mean(label, axis = 1)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.data.persistence_diagrams import get_one_hot_encoded_persistence_diagram_from_gtda\n",
    "\n",
    "# Build list of persistence diagrams so that you can feed them to the Persformer\n",
    "list_of_dgms = []\n",
    "for dgm in dgms:\n",
    "    list_of_dgms.append(get_one_hot_encoded_persistence_diagram_from_gtda(dgm))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build new Dataset\n",
    "\n",
    "Using giotto-deep and torch API it is easy to build a new fully giotto-deep compatible dataset out of the list of peersistence diagrams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PersistenceDiagramFromList(Dataset[Tuple[OneHotEncodedPersistenceDiagram, int]]):\n",
    "    \"\"\"\n",
    "    This data type is acceptsble for Persformer. It gets the data from\n",
    "    a list of diagrams.\n",
    "    \n",
    "    Args:\n",
    "        x: \n",
    "            The input list\n",
    "        y:\n",
    "            The label list\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 x: List[OneHotEncodedPersistenceDiagram],\n",
    "                 y: List[int]\n",
    "                 ):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the length of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            The length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[OneHotEncodedPersistenceDiagram, int]:\n",
    "        \"\"\"\n",
    "        Return the item at the specified index.\n",
    "        \n",
    "        Args:\n",
    "            index: \n",
    "                The index of the item.\n",
    "            \n",
    "        Returns:\n",
    "            The item at the specified index.\n",
    "        \"\"\"\n",
    "        diagram = self.x[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        return diagram, label\n",
    "\n",
    "# the dataset\n",
    "dataset = PersistenceDiagramFromList(list_of_dgms, actual_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataLoader\n",
    "\n",
    "This is the final step for the preparation of the data: build DataLoaders out of datasets, as this is the object needed for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdeep.data.datasets import DataLoaderBuilder\n",
    "from gdeep.data.persistence_diagrams import collate_fn_persistence_diagrams\n",
    "\n",
    "# do not forget the collate function!!\n",
    "db = DataLoaderBuilder([dataset])\n",
    "dl_train, _, _ = db.build([{\"batch_size\": 12, \"collate_fn\": collate_fn_persistence_diagrams}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "We build the *Persformer*: we try to make it reasonably large, even if the dataset is small, as the goal is to overfit rather than making a generalisable classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model by using a Wrapper for the Persformer model\n",
    "\n",
    "wrapped_model = PersformerWrapper(\n",
    "    num_attention_layers=2,\n",
    "    num_attention_heads=8,\n",
    "    input_size= 2 + 2,\n",
    "    output_size=2,\n",
    "    pooler_type=PoolerType.ATTENTION,\n",
    "    hidden_size=16,\n",
    "    intermediate_size=16,\n",
    ")\n",
    "writer = GiottoSummaryWriter()\n",
    "\n",
    "loss_function =  nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(wrapped_model, [dl_train, dl_train, dl_train], loss_function, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train\n",
    "\n",
    "We are now training the model: again, the goal would be to overfit the model, as in this way we would know that there is enough information in the topological representation to perform the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model for one epoch\n",
    "trainer.train(SGD, 30,\n",
    "              lr_scheduler=ExponentialLR,\n",
    "              scheduler_params={\"gamma\": 0.9},)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the results\n",
    "\n",
    "Thanks to `giotto-deep`, we can actually build Saliency maps and display the importance score on top of the diagrams points. Hence, the color of each point indicates how relevant a topological feature is in the classification of the whole task.\n",
    "\n",
    "These saliencies will guide us on where the relevant topological information is stored and how to build a simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a datum and its corresponding class\n",
    "batch = next(iter(dl_train))\n",
    "datum = batch[0][0][0].reshape(1, *(batch[0][0][0].shape))\n",
    "class_ = batch[1][0].item()\n",
    "\n",
    "\n",
    "# we now use the Saliency maps to interpret the results\n",
    "inter = Interpreter(trainer.model, method=\"Saliency\")\n",
    "\n",
    "# interpret the diagram\n",
    "x, attr = inter.interpret(x=datum, y=class_)\n",
    "\n",
    "# visualise the results\n",
    "vs = Visualiser(trainer)\n",
    "out = vs.plot_attributions_persistence_diagrams(inter)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what would be the suggestion for the wrong class?\n",
    "class_ = (batch[1][0].item()+1) % 2\n",
    "print(class_)\n",
    "\n",
    "# interpret the diagram\n",
    "x2, attr2 = inter.interpret(x=datum, y=class_)\n",
    "\n",
    "# visualise the results\n",
    "vs = Visualiser(trainer)\n",
    "out2 = vs.plot_attributions_persistence_diagrams(inter)\n",
    "\n",
    "out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "In this simple classification task, we can check the confusion matrix to make sure that there are no major issues. This can be done in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safety checks on the training performance\n",
    "trainer.evaluate_classification(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
